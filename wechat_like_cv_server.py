# -*- coding: utf-8 -*-
# wechat-like-cv-server.py - è§†è§‰è®¡ç®—ä¸­å¿ƒï¼ˆæ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼‰
import uvicorn
import cv2
import numpy as np
import time
import logging
from fastapi import FastAPI, File, UploadFile, Form

# æ—¥å¿—é…ç½®ï¼ˆæ›´è¯¦ç»†ï¼‰
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - [SERVER] - %(levelname)s - %(message)s')
logger = logging.getLogger("VisionServer")

app = FastAPI()
sift_engine = cv2.SIFT_create()
# FLANN å‚æ•°ï¼šä½¿ç”¨ KD-Tree ç´¢å¼•åŠ é€Ÿ
index_params = dict(algorithm=1, trees=5)
search_params = dict(checks=50)
flann_matcher = cv2.FlannBasedMatcher(index_params, search_params)

def algorithm_sift(template_img, target_img):
    """SIFT ç‰¹å¾åŒ¹é…ï¼Œè¿”å›ä¸­å¿ƒåæ ‡å’Œå¤–æ¥çŸ©å½¢"""
    t0 = time.time()
    logger.debug("å¼€å§‹ SIFT åŒ¹é…...")
    
    # 1. æ£€æµ‹ç‰¹å¾ç‚¹
    kp1, des1 = sift_engine.detectAndCompute(template_img, None)
    kp2, des2 = sift_engine.detectAndCompute(target_img, None)
    
    if des1 is None or des2 is None or len(kp1) < 5:
        logger.warning("ç‰¹å¾ç‚¹ä¸è¶³ï¼Œæ— æ³•åŒ¹é…")
        return None
    
    # 2. KNN åŒ¹é…
    matches = flann_matcher.knnMatch(des1, des2, k=2)
    good_matches = [m for m, n in matches if m.distance < 0.75 * n.distance]
    logger.debug(f"å¥½åŒ¹é…ç‚¹æ•°: {len(good_matches)}")
    
    # 3. å•åº”æ€§çŸ©é˜µè®¡ç®— (è‡³å°‘6ä¸ªç‚¹)
    if len(good_matches) >= 6:
        src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)
        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)
        
        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
        
        if M is not None:
            h, w = template_img.shape
            pts = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)
            dst = cv2.perspectiveTransform(pts, M)
            
            x_coords = dst[:, 0, 0]
            y_coords = dst[:, 0, 1]
            
            # è®¡ç®—å¤–æ¥çŸ©å½¢
            rect = [int(min(x_coords)), int(min(y_coords)), int(max(x_coords)), int(max(y_coords))]
            cx = int(np.mean(x_coords))
            cy = int(np.mean(y_coords))
            
            logger.info(f"SIFT åŒ¹é…æˆåŠŸ | è€—æ—¶: {(time.time()-t0)*1000:.1f}ms | ä½ç½®: ({cx}, {cy})")
            return {"pos": [cx, cy], "rect": rect}
            
    logger.warning("å•åº”æ€§çŸ©é˜µè®¡ç®—å¤±è´¥")
    return None

@app.post("/vision/process")
async def process_image(
    mode: str = Form(...), 
    target: UploadFile = File(...), 
    template: UploadFile = File(None)
):
    logger.info(f"æ¥æ”¶åˆ° HTTP è¯·æ±‚ | æ¨¡å¼: {mode}")
    try:
        # è¯»å–ä¸Šä¼ å›¾ç‰‡
        target_bytes = await target.read()
        img_target = cv2.imdecode(np.frombuffer(target_bytes, np.uint8), cv2.IMREAD_COLOR)
        img_target_gray = cv2.cvtColor(img_target, cv2.COLOR_BGR2GRAY)
        logger.debug(f"ç›®æ ‡å›¾åƒå°ºå¯¸: {img_target.shape}")
        
        result = {"success": False}
        
        if mode == 'sift' and template:
            tpl_bytes = await template.read()
            img_tpl = cv2.imdecode(np.frombuffer(tpl_bytes, np.uint8), cv2.IMREAD_GRAYSCALE)
            logger.debug(f"æ¨¡æ¿å›¾åƒå°ºå¯¸: {img_tpl.shape}")
            
            data = algorithm_sift(img_tpl, img_target_gray)
            if data:
                result = {"success": True, "data": data}
                logger.info("å¤„ç†æˆåŠŸï¼Œè¿”å›ç»“æœ")
            else:
                logger.warning("SIFT åŒ¹é…å¤±è´¥")
                
        return result
    except Exception as e:
        logger.error(f"å¤„ç†é”™è¯¯: {e}")
        return {"success": False, "error": str(e)}

if __name__ == "__main__":
    logger.info("ğŸš€ å¯åŠ¨è§†è§‰æœåŠ¡å™¨...")
    uvicorn.run(app, host="0.0.0.0", port=9000, log_level="debug")
    logger.info("æœåŠ¡å™¨è¿è¡Œä¸­...")